# Kotoba Recipes to run on AzureML

This `azureml` folder is mounted on an Azure ML Compute Cluster.
<br>The folders and files in this azureml directory were copied from the original repository and modified to run in the Azure ML environment.

## Running Pretraining on AzureML

The training script `Pretrain.ipynb` has been confirmed to run on a **2-node** AzureML compute cluster using the `Standard_NC40ads_H100_v5`.
<br>Currently, the job runs as a data-parallel distributed job.

### Preparing the Training Dataset

`wikidump.ipynb` is provided as a sample notebook for preparing the training dataset. The dataset must be formatted as a JSON Lines (`.jsonl`) file, where each line follows the format:

```json
{"text": "<text data>"}
```

### Preparing Index Files

Run `prepare-index.ipynb` first to generate the `.idx` and `.bin` files required for training. This notebook expects the files to be named:

- `wikidump.jsonl`
- `wikidump.idx`
- `wikidump.bin`

### Pretraining LLaMA 3–8B-Instruct

`Pretrain.ipynb` is configured to pretrain the LLaMA 3–8B-Instruct model.

According to the original repository, you should download the checkpoint files from Hugging Face and store them in the Azure Blob Storage container specified by the `model_dir` parameter in the script.

The current configuration also assumes that the training dataset is stored in the Blob Storage folder specified by the `train_data` parameter. This should point to the output folder generated by `prepare-index.ipynb`.
