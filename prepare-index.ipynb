{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1747050334801
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#from azure.ai.ml import MLClient, Input, MpiDistribution, command\n",
        "from azure.ai.ml import MLClient, Input, Output, PyTorchDistribution, command\n",
        "from azure.ai.ml.entities import AmlCompute, Environment, BuildContext, Data\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(override=True)\n",
        "\n",
        "# Azure ML workspace configuration\n",
        "SUBSCRIPTION_ID = os.getenv(\"SUBSCRIPTION_ID\")\n",
        "RESOURCE_GROUP = os.getenv(\"RESOURCE_GROUP\")\n",
        "WORKSPACE_NAME = os.getenv(\"WORKSPACE_NAME\")\n",
        "COMPUTE_CLUSTER = \"demo-gpucluster01\"\n",
        "\n",
        "# authentication via managed identity or service principal (no hard-coded creds)\n",
        "ml_client = MLClient(DefaultAzureCredential(), SUBSCRIPTION_ID, RESOURCE_GROUP, WORKSPACE_NAME)\n",
        "\n",
        "# ensure compute cluster exists or create it\n",
        "try:\n",
        "    ml_client.compute.get(COMPUTE_CLUSTER)\n",
        "except Exception:\n",
        "    print(\"demo-gpucluster01 was not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1747050409131
        }
      },
      "outputs": [],
      "source": [
        "# job configuration\n",
        "NUM_NODES = 1\n",
        "NUM_GPU_PER_NODE = 1\n",
        "\n",
        "# define distributed training job\n",
        "dist = PyTorchDistribution(\n",
        "    process_count_per_instance=NUM_GPU_PER_NODE,\n",
        "    node_count=NUM_NODES\n",
        ")\n",
        "\n",
        "job = command(\n",
        "    code=\"./azureml\",\n",
        "    command=(\n",
        "        \"python megatron_lm/tools/preprocess_data.py \\\n",
        "        --input ${{inputs.train_data}} \\\n",
        "        --output-prefix ${{outputs.indexed}}/wikidump \\\n",
        "        --tokenizer-type Llama2Tokenizer \\\n",
        "        --tokenizer-model ${{inputs.model_dir}} \\\n",
        "        --workers 1 && \"\n",
        "        \"cp ${{inputs.train_data}} ${{outputs.indexed}} && \"\n",
        "        \"mv ${{outputs.indexed}}/wikidump_text_document.bin ${{outputs.indexed}}/wikidump.jsonl.bin && \"\n",
        "        \"mv ${{outputs.indexed}}/wikidump_text_document.idx ${{outputs.indexed}}/wikidump.jsonl.idx\"\n",
        "    ),\n",
        "    inputs={\n",
        "        \"train_data\": Input(\n",
        "            type=AssetTypes.URI_FILE, \n",
        "            path=\"wiki_dump@latest\"\n",
        "        ),\n",
        "        \"model_dir\": Input(\n",
        "            type=AssetTypes.URI_FOLDER, \n",
        "            path=\"llama3-8b@latest\"\n",
        "        )\n",
        "    },\n",
        "    outputs={\n",
        "        \"indexed\": Output(\n",
        "            type=AssetTypes.URI_FOLDER,\n",
        "            path=\"azureml://datastores/workspaceblobstore/paths/wiki-indexed-dataset1/\",\n",
        "            mode=\"rw_mount\"\n",
        "        )                      # 次のジョブからマウント可能\n",
        "    },\n",
        "    environment=\"llama3-8b-wiki_env@latest\",\n",
        "    compute=COMPUTE_CLUSTER,\n",
        "    instance_count=NUM_NODES,\n",
        "    distribution=dist,\n",
        "    environment_variables={\n",
        "        \"LOGLEVEL\": \"INFO\",\n",
        "        \"NCCL_DEBUG\": \"WARN\",\n",
        "        \"NCCL_DEBUG_SUBSYS\": \"WARN\",\n",
        "        \"PYTHONFAULTHANDLER\": \"1\",\n",
        "        \"CUDA_LAUNCH_BLOCKING\": \"0\"\n",
        "    },\n",
        "    display_name=\"llama3-8b-wiki-index\",\n",
        "    experiment_name=\"llama3-8b-wiki-index-exp\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1747050764449
        }
      },
      "outputs": [],
      "source": [
        "# submit the job\n",
        "returned_job = ml_client.jobs.create_or_update(job)\n",
        "print(f\"Job submitted: {returned_job.name}\")\n",
        "print(f\"Monitor at: {returned_job.studio_url}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
